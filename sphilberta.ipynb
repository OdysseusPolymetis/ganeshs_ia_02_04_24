{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/ganeshs_ia_02_04_24/blob/main/sphilberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NtVNJZm3Aho"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EggADLise4v8"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUmm2Tzve1Os"
      },
      "outputs": [],
      "source": [
        "# Chargement du modèle\n",
        "model = SentenceTransformer(\"bowphs/SPhilBerta\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACrxAK0M2zB3",
        "outputId": "a7b55a12-a939-4133-d602-bdddbb37bc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résumé de l'embedding: Somme des valeurs = 5.299886703491211\n",
            "Score de similarité : 0.9692979454994202\n"
          ]
        }
      ],
      "source": [
        "# Phrases en grec ancien et en latin\n",
        "greek_sentence = '''περὶ μὲν οὖν τούτων δεδήλωται καὶ πρότερον·'''\n",
        "latin_sentence = '''id quod iam supera tibi saepe ostendimus ante.'''\n",
        "\n",
        "# Obtention des embeddings pour chaque phrase\n",
        "greek_embedding = model.encode(greek_sentence)\n",
        "latin_embedding = model.encode(latin_sentence)\n",
        "embedding_array = greek_embedding.cpu().numpy() if isinstance(greek_embedding, torch.Tensor) else greek_embedding\n",
        "    # Imprimer une représentation simplifiée de l'embedding, comme la somme des valeurs\n",
        "print(f\"Résumé de l'embedding: Somme des valeurs = {np.sum(embedding_array)}\")\n",
        "\n",
        "# Fonction pour calculer la similarité cosinus\n",
        "def cosine_similarity(a, b):\n",
        "    a = torch.tensor(a)\n",
        "    b = torch.tensor(b)\n",
        "    return torch.nn.functional.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0)).item()\n",
        "\n",
        "# Calcul de la similarité entre les deux phrases\n",
        "similarity_score = cosine_similarity(greek_embedding, latin_embedding)\n",
        "print(\"Score de similarité :\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvmJcyQGPNS"
      },
      "source": [
        "# Démonstration sur quelque chose de plus large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tigdNvB626s1",
        "outputId": "476ec80b-3a30-4188-8a9e-ce2bc446f82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'canonical-greekLit'...\n",
            "remote: Enumerating objects: 63292, done.\u001b[K\n",
            "remote: Total 63292 (delta 0), reused 0 (delta 0), pack-reused 63292\u001b[K\n",
            "Receiving objects: 100% (63292/63292), 557.61 MiB | 15.04 MiB/s, done.\n",
            "Resolving deltas: 100% (41862/41862), done.\n",
            "Updating files: 100% (2650/2650), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PerseusDL/canonical-greekLit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4wJTJl9GV9F",
        "outputId": "2e6b8fef-5c46-42d9-c632-2c71a3c028a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'canonical-latinLit'...\n",
            "remote: Enumerating objects: 25788, done.\u001b[K\n",
            "remote: Counting objects: 100% (1026/1026), done.\u001b[K\n",
            "remote: Compressing objects: 100% (480/480), done.\u001b[K\n",
            "remote: Total 25788 (delta 559), reused 998 (delta 539), pack-reused 24762\u001b[K\n",
            "Receiving objects: 100% (25788/25788), 285.59 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (16253/16253), done.\n",
            "Updating files: 100% (1355/1355), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PerseusDL/canonical-latinLit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KZCs5vEGaLu"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import osgeo\n",
        "import re\n",
        "from lxml import etree\n",
        "from tqdm import tqdm\n",
        "import unicodedata\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import heapq\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2RQvdds6mC8"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KS_TbtsUQf5"
      },
      "outputs": [],
      "source": [
        "!pip install cltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfgp21IPS-L6"
      },
      "outputs": [],
      "source": [
        "from cltk.sentence.lat import LatinPunktSentenceTokenizer\n",
        "from cltk.sentence.grc import GreekRegexSentenceTokenizer\n",
        "from cltk.data.fetch import FetchCorpus\n",
        "\n",
        "corpus_downloader = FetchCorpus(language='lat')\n",
        "corpus_downloader.import_corpus('lat_models_cltk')\n",
        "corpus_downloader = FetchCorpus(language='grc')\n",
        "corpus_downloader.import_corpus('grc_models_cltk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gis3AgbxNMMQ"
      },
      "outputs": [],
      "source": [
        "def extract_sentences_from_descendants(element, nsmap, file_path):\n",
        "    sentences = []\n",
        "\n",
        "    # Sélection du tokenizer en fonction de la langue\n",
        "    if 'lat' in file_path:\n",
        "        sentence_tokenizer = LatinPunktSentenceTokenizer()\n",
        "    elif 'grc' in file_path:\n",
        "        sentence_tokenizer = GreekRegexSentenceTokenizer()\n",
        "    else:\n",
        "        raise ValueError(\"Langue non supportée.\")\n",
        "\n",
        "    for descendant in element.iterdescendants():\n",
        "        if isinstance(descendant.tag, str):\n",
        "            # Extraction du nom de la balise sans l'espace de nom\n",
        "            tag_without_ns = descendant.tag.split('}')[-1]\n",
        "            if tag_without_ns == 'l' or tag_without_ns == 'p':\n",
        "                child_text = etree.tostring(descendant, method=\"text\", encoding=\"unicode\").strip()\n",
        "                # Vérifier si le texte n'est pas vide\n",
        "                if child_text:\n",
        "                    if tag_without_ns == 'l':\n",
        "                        # Pour les balises 'l', ajouter directement le texte\n",
        "                        sentences.append(child_text)\n",
        "                    elif tag_without_ns == 'p':\n",
        "                        # Pour les balises 'p', tokenizer le paragraphe en phrases\n",
        "                        child_sentences = sentence_tokenizer.tokenize(child_text)\n",
        "                        # Filtrer les phrases vides potentielles après le tokenizing\n",
        "                        sentences.extend([sentence for sentence in child_sentences if sentence.strip()])\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def extract_body_content_from_xml(file_path):\n",
        "    parser = etree.XMLParser(recover=True)\n",
        "    tree = etree.parse(file_path, parser)\n",
        "    nsmap = tree.getroot().nsmap\n",
        "    default_ns = nsmap.get(None)\n",
        "\n",
        "    if default_ns:\n",
        "        body = tree.find(\".//{{{}}}body\".format(default_ns))\n",
        "    else:\n",
        "        body = tree.find(\".//body\")\n",
        "\n",
        "    if body is None:\n",
        "        raise ValueError(f\"No <body> element found in {file_path}\")\n",
        "\n",
        "    return extract_sentences_from_descendants(body, nsmap, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig4BYtcraKxn"
      },
      "outputs": [],
      "source": [
        "def extract_texts_from_directory(directory_path, target_authors):\n",
        "    texts = {}\n",
        "    for root, _, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.endswith('.xml') and ('lat' in file or 'grc' in file) and any(author in file for author in target_authors):\n",
        "                content = extract_body_content_from_xml(file_path)\n",
        "                texts[file] = content\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxuCsS_cHcNA"
      },
      "outputs": [],
      "source": [
        "# Endroit où stocker tous les auteurs disponibles\n",
        "grc_target_authors = [\"tlg0059\",\"tlg0086\",\"tlg1325\", \"tlg0626\",\"tlg1304\",\"tlg0632\",\"tlg0591\",\"tlg0593\",\"tlg1562\",\"tlg1705\",\"tlg0014\",\"tlg0610\"]\n",
        "lat_target_authors = [\"phi0474\", \"phi1017\",\"stoa0255\",\"phi1014\",\"tlg0557\",\"phi0550\",\"tlg0628\",\"tlg0562\",\"phi1254\",\"phi1002\",\"stoa0058\",\"phi0684\",\"phi1212\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPsYTfekH7Eq"
      },
      "outputs": [],
      "source": [
        "greek_corpus = extract_texts_from_directory('/content/canonical-greekLit', grc_target_authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BebwLQ6IdAZ"
      },
      "outputs": [],
      "source": [
        "latin_corpus = extract_texts_from_directory('/content/canonical-latinLit', lat_target_authors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij90tSRXVP76",
        "outputId": "9b464b34-12f6-49b9-cd6e-23d711e67936"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84080, 147698)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "total_phrases_grecques = sum(len(phrases) for phrases in greek_corpus.values())\n",
        "total_phrases_latines = sum(len(phrases) for phrases in latin_corpus.values())\n",
        "\n",
        "total_phrases_grecques, total_phrases_latines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI_ITT4gNsMo"
      },
      "outputs": [],
      "source": [
        "# Créer greek_sentences et latin_sentences en filtrant les phrases vides dès le début\n",
        "greek_sentences = [(sentence, file_id) for file_id, sentences in greek_corpus.items() for sentence in sentences if sentence.strip()]\n",
        "latin_sentences = [(sentence, file_id) for file_id, sentences in latin_corpus.items() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "# Créer greek_texts et latin_texts directement à partir des listes filtrées\n",
        "greek_texts = [text for text, _ in greek_sentences]\n",
        "latin_texts = [text for text, _ in latin_sentences]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUSDKXqorweb"
      },
      "source": [
        "## **Encodage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-vHluoyGal9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def check_data_and_encode(model, texts_with_file_id, batch_size=1024):\n",
        "    encoded_data = []\n",
        "    for start_index in tqdm(range(0, len(texts_with_file_id), batch_size), desc=\"Encoding\"):\n",
        "        # Sélectionner un lot de textes à encoder avec leur file_id\n",
        "        batch = texts_with_file_id[start_index:start_index + batch_size]\n",
        "        batch_texts = [text for text, _ in batch]\n",
        "        batch_file_ids = [file_id for _, file_id in batch]\n",
        "\n",
        "        try:\n",
        "            # Encoder le lot de textes\n",
        "            batch_embeddings = model.encode(batch_texts)\n",
        "            # Associer chaque embedding à sa phrase et file_id, puis ajouter au résultat\n",
        "            for text, embedding, file_id in zip(batch_texts, batch_embeddings, batch_file_ids):\n",
        "                encoded_data.append((text, embedding, file_id))\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors de l'encodage du lot de textes de l'indice {start_index} à {start_index + batch_size}\\nErreur: {e}\")\n",
        "\n",
        "    return encoded_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I-EHRAPr10h"
      },
      "outputs": [],
      "source": [
        "greek_encoded_data = check_data_and_encode(model, greek_sentences)\n",
        "#with open('/content/drive/MyDrive/embeddings_save/greek_embeddings_sphilberta.pkl', 'wb') as file:\n",
        "    #pickle.dump(greek_encoded_data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0Wx6MjAtNaQ"
      },
      "outputs": [],
      "source": [
        "latin_encoded_data = check_data_and_encode(model, latin_sentences)\n",
        "#with open('/content/drive/MyDrive/embeddings_save/latin_embeddings_sphilberta.pkl', 'wb') as file:\n",
        "    #pickle.dump(latin_encoded_data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeH3DoPFvAJo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Fonction pour convertir les données en tensors PyTorch et les transférer sur la GPU\n",
        "def to_tensor(data):\n",
        "    phrases, embeddings, file_ids = zip(*data)\n",
        "    embeddings_tensor = torch.tensor(embeddings).float()\n",
        "    if torch.cuda.is_available():\n",
        "        embeddings_tensor = embeddings_tensor.cuda()\n",
        "    return phrases, embeddings_tensor, file_ids\n",
        "\n",
        "greek_phrases, greek_embeddings_tensor, greek_file_ids = to_tensor(greek_encoded_data)\n",
        "latin_phrases, latin_embeddings_tensor, latin_file_ids = to_tensor(latin_encoded_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDuA3Sq52Jd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb08ab8d-8d09-49b2-edde-ce09fc299507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Group Progress: 100%|██████████| 7385/7385 [03:31<00:00, 34.89it/s]\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "latin_group_size = 20\n",
        "\n",
        "# Préparer les tensors pour stocker les indices et les scores de similarité\n",
        "greek_indices_list = []\n",
        "latin_indices_list = []\n",
        "similarity_scores_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Itérer sur les groupes d'embeddings latins\n",
        "    for start_idx in tqdm(range(0, latin_embeddings_tensor.size(0), latin_group_size), desc=\"Group Progress\"):\n",
        "        end_idx = min(start_idx + latin_group_size, latin_embeddings_tensor.size(0))\n",
        "        latin_group = latin_embeddings_tensor[start_idx:end_idx]\n",
        "\n",
        "        # Calculer la matrice de similarité pour le groupe actuel\n",
        "        similarity_matrix = cosine_similarity(greek_embeddings_tensor.unsqueeze(1), latin_group.unsqueeze(0), dim=2)\n",
        "\n",
        "        # Appliquer le seuil de similarité\n",
        "        high_similarity_indices = torch.where(similarity_matrix > 0.7)\n",
        "\n",
        "        # Stocker les indices et les scores de similarité\n",
        "        greek_indices_list.append(high_similarity_indices[0])\n",
        "        latin_indices_list.append(high_similarity_indices[1] + start_idx)  # Ajuster les indices latins selon le groupe\n",
        "        similarity_scores_list.append(similarity_matrix[high_similarity_indices])\n",
        "\n",
        "# Concaténer les listes d'indices et de scores en tensors uniques\n",
        "greek_indices = torch.cat(greek_indices_list)\n",
        "latin_indices = torch.cat(latin_indices_list)\n",
        "similarity_scores = torch.cat(similarity_scores_list)\n",
        "\n",
        "# Convertir en arrays NumPy en une seule opération\n",
        "greek_indices_np = greek_indices.cpu().numpy()\n",
        "latin_indices_np = latin_indices.cpu().numpy()\n",
        "similarity_scores_np = similarity_scores.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_indices = [\n",
        "    idx for idx in tqdm(range(len(similarity_scores_np)), desc=\"Filtrage des indices\")\n",
        "    if len(greek_phrases[greek_indices_np[idx]].split()) > 5 and\n",
        "    len(latin_phrases[latin_indices_np[idx]].split()) > 5 and\n",
        "    similarity_scores_np[idx] < 1\n",
        "]"
      ],
      "metadata": {
        "id": "-a04j40YqOWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from math import log\n",
        "\n",
        "file_pair_similarities = defaultdict(list)\n",
        "\n",
        "for idx in tqdm(filtered_indices, desc=\"Accumulation des similarités\"):\n",
        "    g_idx, l_idx = greek_indices_np[idx], latin_indices_np[idx]\n",
        "    file_pair_key = (greek_file_ids[g_idx], latin_file_ids[l_idx])\n",
        "    file_pair_similarities[file_pair_key].append(similarity_scores_np[idx])\n",
        "\n",
        "# Calculer la moyenne de similarité pour chaque paire de fichiers\n",
        "file_pair_metrics = {\n",
        "    file_pair: (sum(similarities) / len(similarities)) * log(len(similarities))\n",
        "    for file_pair, similarities in tqdm(file_pair_similarities.items(), desc=\"Calcul des métriques composites\")\n",
        "}"
      ],
      "metadata": {
        "id": "-K5uENvIrCeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trier par moyenne de similarité décroissante\n",
        "sorted_file_pairs = sorted(file_pair_metrics.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Prendre les N premiers fichiers pour affichage, par exemple N=5\n",
        "top_file_pairs = sorted_file_pairs[:5]"
      ],
      "metadata": {
        "id": "jFuz2X4XrGOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (g_file, l_file), _ in top_file_pairs:\n",
        "    print(f\"Greek File: {g_file}, Latin File: {l_file}\")\n",
        "\n",
        "    # Filtrer les indices pour ce fichier spécifique\n",
        "    specific_indices = [\n",
        "        idx for idx in filtered_indices\n",
        "        if greek_file_ids[greek_indices_np[idx]] == g_file and latin_file_ids[latin_indices_np[idx]] == l_file\n",
        "    ]\n",
        "\n",
        "    # Trier ces indices par similarité décroissante\n",
        "    specific_indices.sort(key=lambda x: similarity_scores_np[x], reverse=True)\n",
        "\n",
        "    # Afficher les 10 paires de phrases supérieures\n",
        "    for idx in specific_indices[:10]:\n",
        "        print(f\"  Greek Phrase: {greek_phrases[greek_indices_np[idx]]}\")\n",
        "        print(f\"  Latin Phrase: {latin_phrases[latin_indices_np[idx]]}\")\n",
        "        print(f\"  Similarity Score: {similarity_scores_np[idx]}\\n\")\n",
        "\n",
        "    print(\"--------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmuYVXP4rJDW",
        "outputId": "93ee63f1-1c03-483c-86d8-185c116be4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greek File: tlg0086.tlg025.perseus-grc1.xml, Latin File: phi0550.phi001.perseus-lat1.xml\n",
            "  Greek Phrase: δῆλον δʼ ἔσται τὸ λεγόμενον ἐκ τῶν ὕστερον μᾶλλον.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9741785526275635\n",
            "\n",
            "  Greek Phrase: δῆλον δʼ ἔσται τὸ λεγόμενον ἐκ τῶν ὕστερον μᾶλλον.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9741785526275635\n",
            "\n",
            "  Greek Phrase: περὶ μὲν οὖν τούτων δεδήλωται καὶ πρότερον·\n",
            "  Latin Phrase: id quod iam supra tibi paulo ostendimus ante.\n",
            "  Similarity Score: 0.9737507104873657\n",
            "\n",
            "  Greek Phrase: δῆλον δʼ ἔσται τὸ λεγόμενον ἐκ τῶν ὕστερον μᾶλλον.\n",
            "  Latin Phrase: quae tibi posterius largo sermone probabo.\n",
            "  Similarity Score: 0.9700868129730225\n",
            "\n",
            "  Greek Phrase: περὶ μὲν οὖν τούτων δεδήλωται καὶ πρότερον·\n",
            "  Latin Phrase: id quod iam supera tibi saepe ostendimus ante.\n",
            "  Similarity Score: 0.9692978858947754\n",
            "\n",
            "  Greek Phrase: περὶ μὲν οὖν τούτων δεδήλωται καὶ πρότερον·\n",
            "  Latin Phrase: id quod iam supera tibi paulo ostendimus ante.\n",
            "  Similarity Score: 0.9681644439697266\n",
            "\n",
            "  Greek Phrase: διώρισται δὲ περὶ τούτων ἐν ἑτέροις ἡμῖν ἀκριβέστερον.\n",
            "  Latin Phrase: Multaque in his rebus quaeruntur multaque nobis\n",
            "  Similarity Score: 0.9670243263244629\n",
            "\n",
            "  Greek Phrase: περὶ μὲν οὖν τούτων δεδήλωται καὶ πρότερον·\n",
            "  Latin Phrase: clarandumst, plane si res exponere avemus.\n",
            "  Similarity Score: 0.9660218954086304\n",
            "\n",
            "  Greek Phrase: τούτου δὲ πίστις ἐκ τῆς ἐπαγωγῆς.\n",
            "  Latin Phrase: pluribus ostendi et certa ratione probatumst.\n",
            "  Similarity Score: 0.9659479856491089\n",
            "\n",
            "  Greek Phrase: δῆλον δʼ ἔσται τὸ λεγόμενον ἐκ τῶν ὕστερον μᾶλλον.\n",
            "  Latin Phrase: Quod quoniam vinco fieri, nunc esse docebo.\n",
            "  Similarity Score: 0.9651833772659302\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Greek File: tlg0059.tlg030.perseus-grc2.xml, Latin File: phi0474.phi057.perseus-lat1.xml\n",
            "  Greek Phrase: καὶ ἡδέως γʼ ἂν ἀκριβέστερον ἃ λέγεις πυθοίμην.\n",
            "  Latin Phrase: ad ea autem quae requiris brevi\n",
            "            respondebo.\n",
            "  Similarity Score: 0.9658814668655396\n",
            "\n",
            "  Greek Phrase: \n",
            "ἴθι δή, μετὰ ταῦτα τόδε σκέψαι.\n",
            "  Latin Phrase: ea scilicet tu declarabis qui cetera.\n",
            "  Similarity Score: 0.965528130531311\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: ea scilicet tu declarabis qui cetera.\n",
            "  Similarity Score: 0.9622588157653809\n",
            "\n",
            "  Greek Phrase: ἀλλὰ τοῦτο μὲν δὴ καὶ εἰς αὖθις σκεψόμεθα·\n",
            "  Latin Phrase: ea scilicet tu declarabis qui cetera.\n",
            "  Similarity Score: 0.9617613554000854\n",
            "\n",
            "  Greek Phrase: καὶ σκόπει ἐκείνῳ τῷ ἀκριβεῖ λόγῳ·\n",
            "  Latin Phrase: ea scilicet tu declarabis qui cetera.\n",
            "  Similarity Score: 0.961169958114624\n",
            "\n",
            "  Greek Phrase: ἐγώ σοι, εἶπον, ἂν οἷός τε γένωμαι, πειράσομαι διελθεῖν.\n",
            "  Latin Phrase: haec a te invitatus breviter exposui.\n",
            "  Similarity Score: 0.9611281156539917\n",
            "\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: ea scilicet tu declarabis qui cetera.\n",
            "  Similarity Score: 0.9581189155578613\n",
            "\n",
            "  Greek Phrase: καὶ ἡδέως γʼ ἂν ἀκριβέστερον ἃ λέγεις πυθοίμην.\n",
            "  Latin Phrase: haec tu mihi explica qualia sint.\n",
            "  Similarity Score: 0.956989586353302\n",
            "\n",
            "  Greek Phrase: ἀλλά μοι περὶ αὐτῶν τόδε σκόπει.\n",
            "  Latin Phrase: sed haec hactenus, ne videar περὶ.\n",
            "  Similarity Score: 0.9559082984924316\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: sed id quidem, ut tibi videbitur.\n",
            "  Similarity Score: 0.9548537731170654\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Greek File: tlg0059.tlg030.perseus-grc2.xml, Latin File: phi1017.phi015.perseus-lat2.xml\n",
            "  Greek Phrase: καὶ ἡδέως γʼ ἂν ἀκριβέστερον ἃ λέγεις πυθοίμην.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9713366031646729\n",
            "\n",
            "  Greek Phrase: ἀλλὰ τόδε μοι πειρῶ ἔτι πρὸς τούτοις ἀποκρίνασθαι·\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9665537476539612\n",
            "\n",
            "  Greek Phrase: ἀλλʼ ὅρα εἴ σοι βουλομένῳ ἃ λέγω.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9625887870788574\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.961929440498352\n",
            "\n",
            "  Greek Phrase: εἰ οὖν τι δοκῶ λέγειν καὶ συγχωρεῖς, ἄθρει.\n",
            "  Latin Phrase: Et quidem quam sententiam feram, adtende.\n",
            "  Similarity Score: 0.9618842601776123\n",
            "\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: Quod quaeris a me, liquebat mihi, sic rem edidiceram, per se.\n",
            "  Similarity Score: 0.9525817036628723\n",
            "\n",
            "  Greek Phrase: ἀλλά μοι περὶ αὐτῶν τόδε σκόπει.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9507161378860474\n",
            "\n",
            "  Greek Phrase: σκόπει δὴ εἰ ἄρα τι λέγω.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9493299126625061\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9492961764335632\n",
            "\n",
            "  Greek Phrase: ἐμοὶ μὲν γὰρ ἔν γε τῷ παρόντι ἱκανῶς ἂν ἔχοι.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9485822916030884\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Greek File: tlg0086.tlg010.perseus-grc1.xml, Latin File: phi1017.phi015.perseus-lat2.xml\n",
            "  Greek Phrase: διὸ καὶ ἡμῖν πρῶτον ὡς ἐν τύπῳ ὑποκείσθω ταῦτα.\n",
            "  Latin Phrase: Necesse est ex hac quaestione argumenti causa in alteram transeam.\n",
            "  Similarity Score: 0.9592134952545166\n",
            "\n",
            "  Greek Phrase: καὶ περὶ μὲν τούτων ἐπὶ τοσοῦτον διωρίσθω.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.9549264907836914\n",
            "\n",
            "  Greek Phrase: περὶ μὲν οὖν τούτων ἐπὶ τοσοῦτον εἰρήσθω.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.9543372988700867\n",
            "\n",
            "  Greek Phrase: τοῦτο δʼ ἔτι μᾶλλον διασαφῆσαι πειρατέον.\n",
            "  Latin Phrase: Dicam, si mihi accommodaveris subtilitatem et intentionem tuam.\n",
            "  Similarity Score: 0.9525260925292969\n",
            "\n",
            "  Greek Phrase: τοῦτο δʼ ἔτι μᾶλλον διασαφῆσαι πειρατέον.\n",
            "  Latin Phrase: Necesse est ex hac quaestione argumenti causa in alteram transeam.\n",
            "  Similarity Score: 0.9524632692337036\n",
            "\n",
            "  Greek Phrase: ἀλλὰ περὶ μὲν τούτων καὶ ἄλλοθι καιρὸς ἔσται·\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.9519437551498413\n",
            "\n",
            "  Greek Phrase: ὅπερ καὶ ἄνευ λόγου δοκεῖ πᾶσιν.\n",
            "  Latin Phrase: Sed nec ex se hanc causam habet nec veri similem.\n",
            "  Similarity Score: 0.9502924680709839\n",
            "\n",
            "  Greek Phrase: καὶ περὶ μὲν τούτων ἐπὶ τοσοῦτον εἰρήσθω.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.9499818682670593\n",
            "\n",
            "  Greek Phrase: τοῦτο δʼ ἔτι μᾶλλον διασαφῆσαι πειρατέον.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.947458028793335\n",
            "\n",
            "  Greek Phrase: ἀναλαβοῦσι δὴ τὰ προειρημένα συντομώτερος ἂν εἴη ὁ λόγος.\n",
            "  Latin Phrase: Multum autem ad rem pertinet, quo proposito ad quamquam rem accedas.\n",
            "  Similarity Score: 0.9459066987037659\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Greek File: tlg0059.tlg030.perseus-grc2.xml, Latin File: phi0550.phi001.perseus-lat1.xml\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: hinc licet advertas animum, ut pernoscere possis.\n",
            "  Similarity Score: 0.9755781888961792\n",
            "\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9730485081672668\n",
            "\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9730485081672668\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: Quod quoniam docui, pergam conectere rem quae\n",
            "  Similarity Score: 0.9710937738418579\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: Quod quoniam docui, pergam conectere rem quae\n",
            "  Similarity Score: 0.9710937738418579\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: id quod iam supra tibi paulo ostendimus ante.\n",
            "  Similarity Score: 0.9699331521987915\n",
            "\n",
            "  Greek Phrase: μανθάνω τοίνυν ἤδη, ἔφη, καὶ δοκεῖ μοι οὕτω.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9685649275779724\n",
            "\n",
            "  Greek Phrase: μανθάνω τοίνυν ἤδη, ἔφη, καὶ δοκεῖ μοι οὕτω.\n",
            "  Latin Phrase: id licet hinc quamvis hebeti cognoscere corde.\n",
            "  Similarity Score: 0.9685649275779724\n",
            "\n",
            "  Greek Phrase:    \n",
            "ὅρα δὴ καὶ εἰ τόδε πρὸς τρόπου λέγω.\n",
            "  Latin Phrase: id quod iam supera tibi paulo ostendimus ante.\n",
            "  Similarity Score: 0.9679971933364868\n",
            "\n",
            "  Greek Phrase: καὶ τοῦτο, ἦ δʼ ὅς, ἔτι δέομαι σαφέστερον μαθεῖν.\n",
            "  Latin Phrase: Quod quoniam docui, pergam conectere rem quae\n",
            "  Similarity Score: 0.9679224491119385\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auteurs = [\n",
        "    (\"Thalès\", \"tlg1705\", -624, -546),\n",
        "    (\"Pythagore\", \"tlg0632\", -570, -495),\n",
        "    (\"Héraclite\", \"tlg0626\", -535, -475),\n",
        "    (\"Parménide\", \"tlg1562\", -515, -450),\n",
        "    (\"Alcidamas\", \"tlg0610\", -450, -400),\n",
        "    (\"Antisthène\", \"tlg0591\", -445, -365),\n",
        "    (\"Platon\", \"tlg0059\", -427, -347),\n",
        "    (\"Démocrite\", \"tlg1304\", -460, -370),\n",
        "    (\"Aristote\", \"tlg0086\", -384, -322),\n",
        "    (\"Diogène de Sinope\", \"tlg1325\", -413, -324),\n",
        "    (\"Gorgias de Léontium\", \"tlg0593\", -480, -375),\n",
        "    (\"Démosthène\", \"tlg0014\", -384, -322),\n",
        "    (\"Cicéron\", \"phi0474\", -106, -43),\n",
        "    (\"Lucrèce\", \"phi0550\", -99, -55),\n",
        "    (\"Varron\", \"phi0684\", -116, -27),\n",
        "    (\"Sénèque\", \"phi1017\", -4, 65),\n",
        "    (\"Sénèque\", \"stoa0255\", -4, 65),\n",
        "    (\"Sénèque\", \"phi1014\", -4, 65),\n",
        "    (\"Épictète\", \"tlg0557\", 50, 135),\n",
        "    (\"Musonius Rufus\", \"tlg0628\", 20, 101),\n",
        "    (\"Quintilien\", \"phi1002\", 35, 100),\n",
        "    (\"Marc Aurèle\", \"tlg0562\", 121, 180),\n",
        "    (\"Apulée\", \"phi1212\", 124, 170),\n",
        "    (\"Aulu Gelle\", \"phi1254\", 125, 180),\n",
        "    (\"Boèce\", \"stoa0058\", 477, 524)\n",
        "]"
      ],
      "metadata": {
        "id": "xRVSL76xrMYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyP90pBOiBwer8yyY71Zuxiw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}